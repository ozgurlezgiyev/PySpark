# -*- coding: utf-8 -*-
"""Reported_Crimes.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XPOwxW5VgkEjZ8Vpe1mWRjOIiK0xRnSf

# Schemas

## Download and install Spark
"""

!ls

!apt-get update
!apt-get install openjdk-8-jdk-headless -qq > /dev/null
!wget -q http://archive.apache.org/dist/spark/spark-2.3.1/spark-2.3.1-bin-hadoop2.7.tgz
!tar xf spark-2.3.1-bin-hadoop2.7.tgz
!pip install -q findspark

"""## Setup environment"""

import os
os.environ["JAVA_HOME"] = "/usr/lib/jvm/java-8-openjdk-amd64"
os.environ["SPARK_HOME"] = "/content/spark-2.3.1-bin-hadoop2.7"

import findspark
findspark.init()
from pyspark import SparkContext
sc = SparkContext.getOrCreate()

import pyspark
from pyspark.sql import SparkSession
spark = SparkSession.builder.getOrCreate() 
spark

"""## Downloading and preprocessing Chicago's Reported Crime Data"""

!wget https://data.cityofchicago.org/api/views/ijzp-q8t2/rows.csv?accessType=DOWNLOAD
!ls -l

!mv rows.csv\?accessType\=DOWNLOAD reported-crimes.csv
!ls -l

from pyspark.sql.functions import to_timestamp,col,lit
rc = spark.read.csv('reported-crimes.csv',header=True).withColumn('Date',to_timestamp(col('Date'),'MM/dd/yyyy hh:mm:ss a')).filter(col('Date') <= lit('2018-11-11'))
rc.show(5)

"""## Schemas"""

rc.printSchema()

from pyspark.sql.types import StructField, StructType, TimestampType, StringType, BooleanType, DoubleType, IntegerType

rc.columns

labels = [
    ('ID', StringType()),
 ('Case Number', StringType()),
 ('Date', TimestampType()),
 ('Block', StringType()),
 ('IUCR', StringType()), 
 ('Primary Type', StringType()),
 ('Description', StringType()),
 ('Location Description', StringType()),
 ('Arrest', StringType()),
 ('Domestic', BooleanType()),
 ('Beat', StringType()),
 ('District', StringType()),
 ('Ward', StringType()),
 ('Community Area', StringType()),
 ('FBI Code', StringType()),
 ('X Coordinate', StringType()),
 ('Y Coordinate', StringType()),
 ('Year', IntegerType()),
 ('Updated On', StringType()),
 ('Latitude', DoubleType()),
 ('Longitude', DoubleType()),
 ('Location' , StringType()),
]

schema = StructType([StructField (x[0], x[1], True) for x in labels])

rc = spark.read.csv('reported-crimes.csv', schema=schema)

rc.printSchema()

rc.show(5)

"""#Working with columns
##Displaying only the first 5 rows of the column name IUCR
"""

rc.select('IUCR').show(5)

rc.select(rc.IUCR).show(5)

rc.select(col('IUCR')).show(5)

rc.select('Case Number', 'Date', 'Arrest').show(4)

"""##Adding a column with name One with entries all 1s"""

from pyspark.sql.functions import lit

rc.withColumn('One', lit(1)).show(5)

"""#Removing the column IUCR"""

rc.drop('IUCR')
rc.show(5)

#Working with rows
##Adding the reported crimes for an additional day, 12-Nov-2018, to our dataset.

one_day = spark.read.csv('reported-crimes.csv',header=True).withColumn('Date',to_timestamp(col('Date'),'MM/dd/yyyy hh:mm:ss a')).filter(col('Date') == lit('2018-11-12'))
one_day.count()

rc.union(one_day).orderBy('Date', ascending= False).show(5)

rc.groupBy('Primary Type').count().show()

rc.groupBy('Primary Type').count().orderBy('count', ascending=False).show(10)

"""##Find the percentage of reported crimes that resulted in an arrest"""

rc.select('Arrest').distinct().show()

rc.printSchema()

rc.filter(col('Arrest') == True).count() / rc.select('Arrest').count()

"""##Find the top 3 locations for reported crimes"""

rc.groupBy('Location Description').count().show()

rc.groupBy('Location Description').count().orderBy('count', ascending=False).show(3)

"""##Built-in Functions"""

from pyspark.sql import functions

print(dir(functions))

"""##String Functions
Display the Primary Type column in lower and upper characters, and the first 4 characters of the column
"""

from pyspark.sql.functions import lower, upper, substring

help(substring)

rc.printSchema()

rc.select(lower(col('Primary Type')), upper(col('Primary Type')), substring(col('Primary Type'),1,4)).show(5)

"""##Numeric Funtions
Show the oldest date and the most recent date
"""

from pyspark.sql.functions import min,max

rc.select(min(col('Date')),max(col('Date'))).show(1)

"""##Date Functions
What is 3 days earlier than the oldest date and 3 days later than the most recent date
"""

from pyspark.sql.functions import date_add, date_sub

help(date_add)

rc.select(date_sub(min(col('Date')),3),date_add(max(col('Date')),3)).show(1)

"""##Joins
Download police station data
"""

!wget -O police-station.csv https://data.cityofchicago.org/api/views/z8bn-74gv/rows.csv?accessType=DOWNLOAD
!ls -1

ps = spark.read.csv('police-station.csv', header=True)
ps.show(5)

"""The reported crimes dataset has only district number. Add the district name by joining with the police station dataset"""

rc.cache()
rc.count()

ps.select(col('DISTRICT')).distinct().show(30)

rc.select('District').distinct().show(30)

from pyspark.sql.functions import lpad

ps.select(lpad(col('DISTRICT'),3,'0')).show()

ps = ps.withColumn('Format_district', lpad(col('DISTRICT'),3,'0'))
ps.show(5)

rc.join(ps, rc.District == ps.Format_district, 'left_outer').drop(
'ADDRESS',
'CITY',
'STATE',
'ZIP',
'WEBSITE',
'PHONE',
'FAX',
'TTY',
'X COORDINATE',
'Y COORDINATE',
'LATITUDE',
'LONGITUDE',
'LOCATION',
).show()

"""## Challenge questions
**What is the most frequently reported non-criminal activity?**
"""

nc = rc.filter((col('Primary Type') == 'NON - CRIMINAL') | (col('Primary Type') == 'NON-CRIMINAL')  | (col('Primary Type') == 'NON - CRIMINAL (SUBJECT SPECIFIED)'))
nc.show(50)

nc.groupBy(col('Description')).count().orderBy('count', ascending=False).show(truncate=False)

"""**Using a bar chart, plot which day of the week has the most number of reported crime.**"""

from pyspark.sql.functions import dayofweek, date_format

rc.groupBy(date_format(col('Date'), 'E')).count().orderBy('count', ascending=False).show()

dow = [x[0] for x in rc.groupBy(date_format(col('Date'), 'E')).count().collect()]
dow

cnt = [x[1] for x in rc.groupBy(date_format(col('Date'), 'E')).count().collect()]
cnt

import pandas as pd
import matplotlib.pyplot as plt

cp = pd.DataFrame({'Day_of_week': dow, 'Count': cnt})
cp.head(7)

cp.sort_values('Count', ascending=False).plot(kind='bar', color='black', x='Day_of_week', y='Count')
plt.xlabel('Day of week')
plt.ylabel('No. of reported crimes')
plt.title('No. of reported crimes per day of week since 2001')



